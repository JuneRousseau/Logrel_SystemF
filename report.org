# -*- citar-bibliography: ("./biblio.bib"); -*-
#+title: Formalizing logical relation for System F type safety in Coq
#+AUTHOR: June Rousseau
#+OPTIONS: toc:nil
#+LATEX_COMPILER: lualatex
#+LATEX_HEADER: \usepackage[usenames,dvipsnames]{xcolor}
#+LATEX_HEADER: \usepackage{pftools}
#+LATEX_HEADER: \usepackage{circledsteps}
#+LATEX_HEADER: \newcommand{\link}[1]{\href{#1}{\cstep}}
#+LATEX_HEADER: \newcommand{\unit}{\text{unit}}
#+LATEX_HEADER: \newcommand{\unitt}{\text{tt}}

#+LATEX_HEADER: \newcommand{\lrp}[2]{\llbracket #2 \rrbracket_{#1}}
#+LATEX_HEADER: \newcommand{\lr}[3]{\llbracket #2 \rrbracket_{#1}(#3)}
#+LATEX_HEADER: \newcommand{\lrv}[2]{\lr{#1}{#2}{v}}
#+LATEX_HEADER: \newcommand{\typed}[3]{#1 \vdash #2 : #3}
#+LATEX_HEADER: \newcommand{\hstep}{\rightsquigarrow}
#+LATEX_HEADER: \newcommand{\step}{\rightarrow}
#+LATEX_HEADER: \newcommand{\mstep}{\step^{\ast}}
#+LATEX_HEADER: \usepackage{syntaxColor}
#+LATEX_HEADER: \input{macros}
#+LATEX_HEADER: \usepackage{amsthm}
#+LATEX_HEADER: \theoremstyle{plain}
#+LATEX_HEADER: \newtheorem*{theorem*}{Theorem}
#+LATEX_HEADER: \newtheorem*{lemma*}{Lemma}
#+LATEX_HEADER: \newtheorem*{definition*}{Definition}
#+LATEX_HEADER: \usepackage{todonotes}
#+bibliography: biblio.bib
\begin{abstract}
Type safety is a language property that ensuret that any well-typed closed,
program is safe to execute. While syntactic approaches are widely used to
prove type safety, another proof method based on logical relation has been shown
to be efficient to prove such language properties. In the lectures, we have
defined a logical relation and used it to prove type safety of \systemF, on
 paper. Because there are many details, paper proofs are prone to errors.
Moreover, the encoding of some data structures, as well as their properties, are
often implicit. Proof assistant such as Coq require  everything explicit in
the implementation, prove every single property, and help to keep track of
every minute detail. To fill the gap between paper proof and a proof-assistant
implementation, we describe an implementation in Coq of type safety of \systemF,
using logical relation.
\end{abstract}
#+TOC: headlines 2

* Introduction
:PROPERTIES:
:CUSTOM_ID: introduction
:END:
Milner wrote /"Well-typed programs cannot go wrong"/
[cite:@milnerTheoryTypePolymorphism1978].
\todo{to talk about type safety}
Type safety --- also known as /type soundness/ --- is a language property
ensuring that well-typed program are safe. It expresses that the semantic is
complete, in the sense that any well-typed, closed term[fn:term] of the language
will never reach a state about which the semantics says nothing: it is either a
value, or it can perform a step.

A naive approach to prove type safety of a language would be to proceed by
induction on the structure of types. However, this approach fails, because the
induction hypothesis is too weak.
\todo{ better transition sentence}
Type safety is commonly proved using two auxiliary lemmas known as /progress/
and /preservation/
[cite:@wrightSyntacticApproachType1994; @pierceTypesProgrammingLanguages2002].
Informally, the former states that a well-typed expression is not stuck, \ie it
is either a value, or can perform a step. The latter says that if an expression
is well-typed, the next step will also be well-typed.

Another way to prove type safety is based on logical relations. Logical
relations are a proof method that scales better on more expressive language
\todo{check this information}
and that can be used to prove others language properties, such as normalization,
contextual equivalence, or non-interference. Moreover, the fundamental theorem
of logical relations has consequences besides type safety, as deriving free
theorems.

When defining a logical relation, there is plenty of detail to keep track of,
which makes a paper proof prone to miss an important detail. Moreover, the
concrete data structures are sometimes quite implicit. Proof assistants, such as
Coq, make sure that every single properties has been proved. The interactive
theorem prover helps one to keep track of every minute details. Thus, we get
more confidence by implementing logical relation to prove type safety in Coq.
However, the implementation itself brings new challenges, that we will discuss
in this document.

This report is organized as follows.
In section [[#paper-proof]], we formalize on paper the language \systemF, the type
safety property, the logical relation, and we establish the main theorems and
lemmas.
In section [[#implementation]], we present the different implementation options, and
we highlight the challenges of the implementation in Coq, contrasting with the
paper version of the proof.
Finally, in section [[#improvement]], we propose ideas of improvement and
alternatives of the implementation, as well as possible extensions of the
project.

The Coq implementation is available in a [[https://github.com/BastienRousseau/Logrel_\systemF/tree/release][Github repository]].
In the following, we use numbered circles to link the formal statement to the
corresponding Coq code. For the purpose of the presentation, the representation
in the paper and in the code might differ.
[fn:term] In the document, we use "term" and "expression" interchangeably.

* Type safety of \systemF on paper
:PROPERTIES:
:CUSTOM_ID: paper-proof
:END:
In this section, we formalize on paper the language \systemF using a named
representation of the binders. We present the call-by-value (CBV) small-step
semantic and the typing judgment. Then, we formalize type safety, the logical
relation and we formulate the main lemmas and theorem.
Most of the formalization is standard [cite:@timanyLogicalRelationsSafety].

** Language
\input{figures/syntaxSF1}
We consider a variant of \systemF that includes unit and products.
We define the syntax and the operational semantic of the language
in Figure \ref{fig:opsemSF1}.
The named binders are represented as strings. The variable $y$ in the expression
$\pair{\tt}{y}$ is a free variable (not bound to any lambda abstraction), while
the variable $x$ in the expression $\lam{x}{x}$ is bound to the lambda
abstraction. In section [[#implementation]], we show a different representation
of binders, based on the De Bruijn technique, and we explain why the named
representation is not well-suited for implementation.

The dynamic semantics we consider is a small-step operational semantics
with a call-by-value strategy. The notation $\subst{e}{v}{x}$ denotes the
capture-avoiding substitution of the expression variable $x$ by the value $v$.
We denote $\mstep$ the transitive closure of the non-head reduction relation
$\step$. The syntax and the semantics of the language are standard.
\todo{syntax of terms?}
\todo[inline]{$\typed{\tyctx;\ \exprctx}{e}{\ty}$ if the figure}
\input{figures/typingSF1}
Figure \ref{fig:typingSF1} shows the types and the typing rules of \systemF.
We denote $\typed{\tyctx;\ \exprctx}{e}{\ty}$ the typing judgment stating that
/"$e$ is of type $\ty$ under the typing context $\tyctx;\ \exprctx$"/.
$\exprctx$ is the context of expression variables, that associates a type to an
expression variable.
$\tyctx$ is the context of type variables, that gathers the free type variables.
We denote $\empctx$ an empty context. The typing rules are also standard.

With the language properly defined, we can now focus on a property of this
language: type safety.

** Type safety
:PROPERTIES:
:CUSTOM_ID: type-safety
:END:
A term is /safe/ if it never gets stuck after any number of steps. In other words,
any expression, or reduction of the expression, is either a value, or can
perform a step:
\begin{definition*}{Safety}
\[
\safe(e) \eqdef
\forall e'.~e \mstep e' \Rightarrow (e' \in \val) \vee \exists e''.~e' \hstep e''
\]
\end{definition*}
A weaker version of safety is /parameterized safety/. Let $P$ be a predicate
of values. A term is safe according to $P$ if any expression can either
perform a step, or is a value that respects the predicate $P$:
\begin{definition*}{Parameterized safety
\href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/logrel.v#L37}{\cstep}
}
\[
\safe_{P}(e) \eqdef
\forall e'.~e \mstep e' \Rightarrow (e' \in \val \wedge P(v)) \vee \exists e''.~e' \step e''
\]
\end{definition*}
We notice that, for any $P$, $\safe_{P}(e) \Rightarrow \safe(e)$.

A language is /type safe/ when any closed well-typed term is safe:
\begin{theorem*}{Type safety
\href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/logrel.v#L526}{\cstep}
}
\(\forall e,~\ty.~\typed{\empctx}{e}{\ty} \Rightarrow \safe(e)\)
\end{theorem*}

** Logical relation
As pointed out in Section [[#introduction]], type safety of \systemF can be proved
using the syntactic approach of progress and preservation
[cite:@wrightSyntacticApproachType1994], but can also be proved using a logical
relation.
\todo{more explanation for this paragraph}
We denote the logical relations[fn::We can also say /"$v$ is in the logical
relation for the type $\ty$"/]
$\lr{\sctx}{\ty}{v}$, where \(\sctx ::= \empctx\ |\ (\alpha \mapsto P) :: \sctx\) is
a mapping from type variable to an expression property
$P \in (\mathrm{Expr} \rightarrow \PP)$.
We define our logical relation by induction on the structure of types in Figure
\ref{fig:logrelSF}.
\input{figures/logicalrelationSF}

The type safety theorem follows from the composition of two lemmas about the
logical relation:
1. any well-typed closed term is in the logical relation
   \[\forall e,\ \ty.\ \typed{\empctx}{e}{\ty} \Rightarrow \lr{\empctx}{e}{\ty} \]
2. any term in the logical relation is safe
   \[\forall e,\ \ty.\ \lr{\empctx}{e}{\ty} \Rightarrow \safe(e) \]

The second lemma is straightforward, because safety is baked in the
logical relation itself.
\todo{make clearer that this is on purpose, cf skorstengaard}
[cite:@skorstengaardIntroductionLogicalRelations]
The first lemma is the interesting part of the proof. In order to prove it, we
first need to generalize it. The generalized version is called the
*Fundamental Theorem of the Logical Relation* (FTLR).

To define the FTLR, we first need to introduce the semantic substitution.
We denote $\sfun$ a substitution, which maps expression variables to
expressions.
\[\sfun ::= \empctx\ |\ (x \mapsto e) :: \sfun\]

Assuming that the domain of $\sfun$ and $\exprctx$ are equals, we say that /the
substitution $\sfun$ satisfies the typing context $\exprctx$ for the predicate
$P \in \mathrm{Type} \rightarrow \mathrm{Expr} \rightarrow \PP$/, written
$\sfun \Mapsto_{P} \exprctx$, when for all expression variables in $\sfun$,
the predicate $P$ holds for the mapped expression and their corresponding type
in $\exprctx$:
\begin{definition*}{Typing context satisfaction
\href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/logrel.v#L132}{\cstep}
}
\[
\sfun \Mapsto_{P} \exprctx \eqdef \forall x \in \mr{Dom}(\sfun).~P(\sfun(x))(\exprctx(x))
\]
\end{definition*}

The FTLR states that if a closed term is well-typed, the term substituted with
$\sfun$ is in the logical relation, for any $\sfun$ that satisfies the typing
context $\exprctx$ for the logical relation:
\begin{theorem*}{Fundamental Theorem of the Logical Relation
\href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/logrel.v#L394}{\cstep}
}
\[\forall e,\ \ty,\ \tyctx,\ \exprctx.\ \typed{\tyctx;\exprctx}{e}{\ty} \Rightarrow
(\forall \sctx,\ \sfun.\ (\sfun \Mapsto_{P} \exprctx) \Rightarrow \lr{\sctx}{\ty}{\sfun(e)}) \]
with $P = \lambda \ty,~e.~ \lr{\sctx}{\ty}{e}$.
\end{theorem*}

In the end of the section, we highlight some important intermediate lemmas.
We refer the reader to the Coq proof, or the lecture notes
[cite:@timanyLogicalRelationsSafety] for the details.

For any value predicates $P$ and $Q$, and any expression $e$, the $\safe$
predicate is monotone over the parameterized predicate:
\begin{lemma*}{Safe monotonicity
\href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/logrel.v#L41}{\cstep}
}\label{thm:safemono}
\( (\forall v.\ P(v) \Rightarrow Q(v)) \Rightarrow \safe_{P}(e) \Rightarrow \safe_{Q}(e) \)
\end{lemma*}

For any value predicates $P$ that holds for a value $v$, the $\safe$ predicate also
holds:
\begin{lemma*}{Safe value
\href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/logrel.v#L51}{\cstep}
}\label{thm:safeval}
\( P(v) \Rightarrow \safe_{P}(v) \)
\end{lemma*}

For any expression $e$ that steps to an expression $e'$, the $\safe$ predicate
is (backward)-preserved for any value predicate $P$:
\begin{lemma*}{Safe step backward
\href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/logrel.v#L58}{\cstep}
}\label{thm:safestep}
\( e \step e' \Rightarrow \safe_{P}(e') \Rightarrow \safe_{P}(e)\)
\end{lemma*}

To prove that an expression $\ctxh{e}$ is $\safe$, it actually suffices to show that
$\ctxh{v}$ is safe for any value $v$:
\begin{lemma*}{Safe bind
\href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/logrel.v#L72}{\cstep}
}\label{thm:safebind}
\[\forall P\ Q\ e,\ \safe_{Q}(e) \Rightarrow
(\forall v,\ Q(v) \Rightarrow \safe_{P}(\ctxh{v})) \Rightarrow
\safe_{P}(\ctxh{e})) \]
\end{lemma*}

\todo{weird phrasing}
The logical relation of the substitution of the type $\ty'$ in a type $\ty$ is equivalent
to associating the logical relation of $\ty'$ to the corresponding free variable
in $\sctx$:
\begin{lemma*}{Logrel subst
\href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/logrel.v#L385}{\cstep}
}\label{thm:logrelsubst}
\( \lrv{\sctx}{\ty.[\ty'/\alpha]} \Leftrightarrow \lrv{(\alpha \mapsto \lrp{\sctx}{\ty'})::\sctx}{\ty} \)
\end{lemma*}

If $\alpha$ is not free in $\ty$, we can associate any predicate $P$ to $\alpha$ in $\sctx$:
\begin{lemma*}{Logrel weaken
\href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/logrel.v#L302}{\cstep}
}\label{thm:logrelweak}
\( \lrv{\sctx}{\ty} \Leftrightarrow \lrv{(\alpha \mapsto P)::\sctx}{\ty} \)
\end{lemma*}

** Free theorems
The FTLR has other consequences, besides type safety. For instance, it can also
be used to derive free theorems, /Ã  la Wadler/ [cite:@wadlerTheoremsFree1989].
We prove the two following theorems.

Any polymorphic expression that is typed with the identity type
$\tyforall{\alpha}{\tyarrow{\alpha}{\alpha}}$ is the identity function, \ie if we apply
the expression to a value $v$, it will reduce the value $v$
itself, or run forever.
\begin{theorem*}{Polymorphic identity
\href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/free_theorem.v#L8}{\cstep}}
\[\forall e~,v.~\typed{\empctx;\empctx}{e}{\tyforall{\alpha}{\tyarrow{\alpha}{\alpha}}}
\Rightarrow \safe_{(\lambda e.~e = v)}(\app{(\tapp{e})}{v})
\]
\end{theorem*}

Any polymorphic expression that is typed with the type $\tyforall{\alpha}{\alpha}$ is actually
the empty type, which is as expected uninhabited:
\begin{theorem*}{Empty type
\href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/free_theorem.v#L35}{\cstep}}
\[\forall e~,v.~\typed{\empctx;\empctx}{e}{\tyforall{\alpha}{\alpha}}
\Rightarrow \safe_{(\lambda e.~\bot )}(\tapp{e})
\]
\end{theorem*}

* Implementation in Coq
:PROPERTIES:
:CUSTOM_ID: implementation
:END:
In this section, we describe the different implementation options that we had,
and we explain the choices that we made.

** Data structure :noexport:
introduction about the data structure that are implicit (for most of them),
their properties are assumed, etc. But when implement, we need to concrete data
structure and concrete lemmas about them etc.

** Semantic with evaluation context
Our operational semantics of \systemF follows a call-by-value evaluation strategy,
small-step semantic.
We had in mind two possible solutions to implement the reduction relation of
\systemF CBV.
1. A semantic with an explicit reduction rule for every inductive case,
    \href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/syntax_systemF.v}{\cstep}:
    with a single reduction relation which contains all the rules.
2. An evaluation context based semantic in two layers
    \href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/opsem_systemF_ctx.v}{\cstep}:
   a head reduction relation, which expresses how to reduce the expression when
   the redex is in head position; and a non-head reduction relation, when the
   redex is not is the head position. The evaluation context determines where is
   the redex in the term.

The two semantics are equivalent
\href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/opsem_systemF_ctx.v#L131}{\cstep},
and both implementations have their own pros and cons.
On the one hand, the structural induction is easier with the one-step semantic
(1), but the lack of evaluation context prevents defining the
\href{thm:safebind}{safe-bind lemma}.
As a consequence, the binding property has to be defined /on-the-fly/ for each
induction case of the FTLR.
On the other hand, the evaluation context semantic (2) is convenient to define
the \href{thm:safebind}{safe-bind lemma}, but the proof by induction tends to be
more tedious. This is caused by the fact that the semantics has two reduction
relations: in particular, the non-head reduction relation requires us to
destruct the evaluation context.

In the end, both approaches are equivalent in term of proof effort, and the
choice is mainly a matter of taste. We wanted to stick to the lecture notes
[cite:@timanyLogicalRelationsSafety] as much as possible, so we decided to use
the evaluation context semantic to define the logical relation. Moreover,
we show in section [[#improvement]] another argument that scales in favour of the
evaluation context semantic.
\todo{mention Iris?}

** Nameless binders
In the expression $\lam{x}{e}$, we call $\lambda x$ a /binder/. When an expression
variable is bound, we say that it points to a (specific) binder. Named binders
are a way to represent binders, such that all the occurrences of $x$ in
$\lam{x}{e}$ point to the binder $\lambda x$, until another nesting binder with the
same name appears. It is a convenient way to represent the binders, because the
proofs, especially on paper, are more readable. However, this representation has
also some downsides. First, the same term might have different representation,
because \lambda-terms are equal /up-to renaming of the bound variables/. For instance,
$\lam{x}{x}$ represents the same term as $\lam{y}{y}$. Second, we have to make
sure that the substitution is capture-avoiding. Since the proofs are more
readable with named binders, we first tried to use them in the implementation.
At some point, we had to define parallel (or simultaneous) substitution, and
using this definition in the Coq proof was \todo[inline]{a pain...}

The named representation of the binders is not satisfactory when
implementing the language in Coq. The question of the implementation of binders
is a well-known issue when implementing a language
[cite:@pierceTypesProgrammingLanguages2002]. An alternative solution is
to use the DeBruijn representation. It is a canonical, unique and nameless
representation of the binder. Informally, variables point directly to their
binder: the named variables are replaced by a natural number that expresses the
distance to its binder. More precisely, the DeBruijn index /k/ points to the
/k/-th enclosing \lambda.

In a more formal way, the expression expression variables are $k \in \NN$. A
variable $k$ is free when it ranges outside of the enclosing \lambda.
The notation $\subst{e}{v}{}$ is the substitution of the /first/ free variable: it
replaces the free variable 0 --- or under $n$ lambda abstraction, it is
represented by $n$ --- by $v$, and renames (here, renumbers) all the other
variable accordingly, by subtracting.
For instance, in the expression $\subst{\pair{0}{1}}{\tt}{} = \pair{\tt}{0}$,
the first free variable is 0, so it replaces 0 by the expression $\tt$.
Moreover, the next free variable 1 is renamed to 0. In the expression
$\subst{1}{\tt}{} = 0$, the first free variable should be 0 (even if it does not
appear in the expression), so the substitution only performs the renaming.
Finally, in the expression,
$\subst{(\lam{}{\pair{0}{\pair{1}{2}}})}{\tt}{} =
(\lam{}{\pair{0}{\pair{\tt}{1}}})$, the substitution enters the
lambda-abstraction, where the first free variable is now represented as 1.
\todo[inline]{The formal definition of the substitution can be found in the appendix?}
In a similar way, we also use the DeBruijn representation for type variables
$\alpha \in \NN$.

\input{figures/syntaxDB}
Figure \ref{fig:opsemDB} shows the modifications on the syntax due to the new
representation. As type variable are also represented using the De Bruijn
indices, the free variable are the $\alpha$ that range outside the number of
enclosing $\forall$. Thus, there is no need to maintain the type variable context
$\tyctx$. Moreover, the expression variable context becomes an ordered sequence
of types, such that the /k/-th element of the sequence $\exprctx$ is the type of
the free expression variable represented by $k$.

The main modification is in the rule \ruleref{T-TAbs-DeBruijn}.
Indeed, in the rule \ruleref{T-Abs} with named binders, the binder of the type
variable $\alpha$ is added in the context, and makes sure that $\alpha$ does not appear
freely in the context $\exprctx$. If necessary, $\alpha$ can be renamed to a fresh type
variable.
Using De Bruijn representation, the new binder is represented by the type
variable 0. All the type variables in the context $\exprctx$ have to be renamed: it
both ensures that the type points to the right binder, and the freshness of the
new binder. The renaming consists on incrementing the free type variables by 1,
because they are now under one more $\forall$.

The De Bruijn technique has been widely used to represent binders. /autosubst/
[cite:@SchaeferEtAl:2015:Autosubst:-Reasoning] is a Coq library that helps
implement and automate the DeBruijn representation. It automatically derives
and proves some basic lemmas about (parallel) substitution. Moreover, it
provides useful tactics to reason about substitution. Our implementation uses
/autosubst/ to represent binders and leverages the automation to simplify
the proofs, in particular of the \href{thm:logrelsubst}{substitution lemma}
and the \href{thm:logrelweak}{weakening lemma}.

\input{figures/logrelDB}
Figure \ref{fig:logrelDB} highlights the modifications to the logical relation
according to the De Bruijn representation of the binders. In particular, the
mapping $\sctx$ is a sequence of expression properties instead of a mapping of
type variables. Indeed, as we have already done with the context $\Gamma$, the \alpha-th
element of $\sctx$ is the property mapped to the type variable $\alpha$.

\todo{Example of lemma that was hard to prove with named binders, but easier with autosubst}

** Substitution lemmas
One of the most useful properties of the logical relation is the /substitution
lemma/. We recall the substitution lemma below, but with the De Bruijn
representation of the binders.
\begin{lemma*}{Logrel subst - De Bruijn}
\[
\forall \sctx,\ \ty,\ \ty',\ v.\
\lrv{\sctx}{\subst{\ty}{\ty'}{}}
\Leftrightarrow
\lrv{(\lrp{\sctx}{\ty'}::\sctx)}{\ty}
\]
\end{lemma*}
It states that a value $v$ is in the logical relation for the type
$\ty.[\ty'/]$ if and only if we can associate its own logical relation to the
corresponding free type variable in the interpretation mapping.
However, while the string representation of the binder allows to prove this by
straightforward induction on $\ty$, we cannot proceed directly by induction with
our representation based on DeBruijn indices.
The induction hypothesis is actually not strong enough, and the inductive case
for the polymorphic type does not work. Indeed, the induction hypothesis is then
\[
\forall \sctx,\ \ty,\ \ty',\ v.\
\lrv{\sctx}{\subst{\ty}{\ty'}{}}
\Leftrightarrow
\lrv{(\lrp{\sctx}{\ty'}::\sctx)}{\ty}
\]
and therefore the proof obligation for the polymorphic case is
\[
\lrv{\sctx}{\subst{(\tyforall{}{\ty})}{\ty'}{}}
\Leftrightarrow
\lrv{(\lrp{\sctx}{\ty'}::\sctx)}{\tyforall{}{\ty})}
\]
If we unfold the definition of the logical relation and simplify the goal,
the proof obligation ends up being
\[
\lrv{P::\sctx}{\subst{\ty}{\ty'}{}}
\Leftrightarrow
\lrv{P::(\lrp{\sctx}{\ty'}::\sctx)}{\ty}
\]
where an additional predicate $P$ is the head of the mapping $\sctx$.
While we would like to use the induction hypothesis, it is not possible because
the head of the mapping has to be the property of the substituted type variable
$\ty'$.

The solution is then to generalize the substitution lemma, such that the
predicate that maps the substituted type variable $\ty'$ to the logical relation
may be anywhere in the new mapping. At a high level, this means that
the induction has already gone through a certain number of type abstractions
$\tyforall{\ty_{1}} \tyforall{\ty_{2}} \ldots \tyforall{\ty_{n}}$.

\begin{lemma*}{Generalized logrel subst - De Bruijn
\href{https://github.com/BastienRousseau/Logrel_\systemF/blob/599b9e84d6d8f902442e5f85f37522ce21708103/theories/logrel.v#L325}{\cstep}
}
\[
\forall \sctx_{1},\ \sctx_{2},\ \ty',\ v.\
\lrv{ \sctx_{1}++\sctx_{2}}{\subst{\ty}{\mathrm{upn}\ (\mathrm{len }\ \sctx_{1})\ \ty'}{}}
\Leftrightarrow
\lrv{ \sctx_{1}++( \lrp{\sctx_{2}}{\ty'} ::\sctx_{2})}{\ty}
\]
where $\subst{\ty}{\mathrm{upn}\ (\mathrm{len }\ \sctx_{1})\ \ty'}{}$
substitutes $\ty'$ in the type $\ty$ by renaming the variables after
$(\mathrm{len }\ \sctx_{1})$.
\end{lemma*}
It suffices to instantiate the generalized theorem with $\sctx_{1} = \empctx$
to get the original substitution lemma.

** Proving type safety in Coq
With this setup, follow paper proof, but in Coq. Induction on the type judgment.
Biggest difference with names, but all the hurdles has been tackled in the
lemmas.
\todo{what did you do ? does not have to be long. stick pieces together}

* Possible improvement / Future work
:PROPERTIES:
:CUSTOM_ID: improvement
:END:
In this section, we discuss different ways in which the project could be
improved. First, we propose an improvement to make the implementation more
generic and modular. Then, we propose some directions in which we could extend
the project.
Finally, we propose an alternative way to implement a logical relation for type
safety in Coq, which could lead to a convenient way to extend the language with
non-trivial features.

** Language typeclass
\todo{make clear that this is a usual way, eg in Iris}
The main interest of the project was to implement type safety of \systemF in Coq,
using logical relations. In section [[#type-safety]], we defined the
parameterized $\safe$ predicate and a few intermediate lemmas about this
predicate. The $\safe$ predicate does not really depend on the language, unlike
the logical relation, which is defined over the type structure.

We propose to make the implementation more generic and modular, such that we can
define the $\safe$ predicate independently to the language. In a Coq
implementation, it results in the definition of a class that expresses what is a
valid language. A generic language is a tuple of:
- the type of expression of the language $\mr{Expr}$
- a function $\mr{is\_value}: \mr{Expr} \rightarrow \PP$ that expresses which expressions
  are the values of the language
- a function $\mr{head\_step}: \mr{\mr{Expr}} \rightarrow \mr{Expr} \rightarrow \PP$ that expresses
  the head reduction relation
- a function $\mr{is\_ectx}: (\mr{Expr} \rightarrow \mr{Expr}) \rightarrow \PP$ that expresses how to
  determine the evaluation context when the redex is not in head position

The future work is to determine which properties (expressed in terms of the
generic language) are necessary to make the language a /valid/ language.
By valid language, we mean a language that allows one to derive the properties
over the $\safe$ predicate, \ie \href{thm:safemono}{safe-mono},
\href{thm:safeval}{safe-val}, \href{thm:safebind}{safe-bind} and
\href{thm:safestep}{safe-step}.

This improvement brings more modularity in the implementation. One can indeed
define its own language, prove that the language is a valid language and the
typeclass derives automatically the lemmas about the safety.
Our variant of \systemF would be an instance of such valid language.
In this way, we could easily extend the project with type safety of another
language, such as Simply Typed Lambda Calculus (STLC) without proving the safety
lemmas again.

** Other language properties
As mentioned earlier, logical relations are a proof technique that can be used to
prove language properties [cite:@skorstengaardIntroductionLogicalRelations]. We
propose two others properties to extend the project.
*** Normalization
A term normalizes if it reduces to a value. Formally,
\[\norm(e) \eqdef \exists v \in \val.~e \step^{*} v\]
and the parameterized version
\[\norm_{P}(e) \eqdef \exists v \in \val.~e \step^{*} v \wedge P(v)\]

We can derive the lemmas equivalent to \href{thm:safemono}{safe-mono},
\href{thm:safeval}{safe-val}, \href{thm:safebind}{safe-bind} and
\href{thm:safestep}{safe-step} for the $\norm$ predicate. This extension could
leverage the modularity of the previous proposition.

*** Contextual equivalence
Contextual equivalence, or observational equivalence, is a language property
saying that, if two program are contextually equivalent, it does not exist
any context able to differentiate them. It is also a way to derive free
theorems.

Formally, the contextual equivalence is defined as follows:
\[
\typed{\tyctx';\exprctx'}{e_{1} \approx^{\mathrm{ctx}} e_{2} }{\ty'}
\eqdef
 \forall \ctx\ :\ (\tyctx;\exprctx \vdash \ty) \Rightarrow (\empctx;\empctx \vdash \tyunit).\
 (\ctxh{e_{1}} \Downarrow v \Leftrightarrow \ctxh{e_{2}} \Downarrow v)
\]
where $e \Downarrow v \eqdef e \mstep v$ and 
\begin{mathpar}
\inferH
{Ctx-Typing}
{\typed{\tyctx;\exprctx}{e}{\ty}
\\
\typed{\tyctx';\exprctx'}{\ctxh{e}}{\ty'}
}
{ \ctx~:~(\tyctx;\exprctx \vdash \ty) \Rightarrow (\tyctx';\exprctx' \vdash \ty')}
\end{mathpar}

It states that two expressions $e_{1}$ and $e_{2}$ of type $\ty$ are contextually
equivalent if and only if,
for any context that has a hole of type $\ty$, and produces a closed expression of
type $\tyunit$ (see \ruleref{Ctx-Typing}), filling the hole with $e_{1}$ or $e_{2}$
will both reduces to the same value $v$ (which actually has to be $\tt$).

** Logical relation using Iris
Iris [cite:@IrisProject; @jungIrisGroundModular2018] is a higher-order
separation logic framework, implemented and verified in Coq. Iris as been shown
to be an efficient framework to implement logical relation. In particular, an
alternative way to implement the logical relation and prove type soundness of
\systemF [cite:@timanyLogicalApproachType2022] could have been to use the Iris
framework.

A possible extension of \systemF is to add recursive types. However,
[cite:@skorstengaardIntroductionLogicalRelations] has shown
that adding recursive types is a feature that leads to a non-trivial extension of
the logical relation: indeed, we have defined the logical relation inductively
on the structure of type, but unfolding a recursive type does not guarantee the
resulting type to be smaller than the folded one. Thus, it is impossible to
simply extend the logical relation defined in this project.
Similarly, another extension of the language is to add mutable state (for
instance, with pointers)
[cite:@ahmedSemanticsTypesMutable2004; @skorstengaardLogicalRelationsReferences2016]
which leads to a similar issue (we can encode recursion through the heap,
thanks to the Landin's knot technique).

However, Iris is a step-indexed logic. It provides the logical tools to easily
manage recursive types. Moreover, because Iris is a logic of resources, it
allows to define resources describing the heap, and easily implement mutable
state.

** Logical relation as an interpretation of types
\todo{develop more}
Another way to understand the logical relation is to see the logical relation as
an interpretation of types. Indeed, the logical relation for the type $\ty$
can be actually seen as the set of expression that behaves as the type $\ty$.
In his notes about logical relation [cite:@sterlingPracticalSemantics], Jon
Sterling points out that some work can be performed in order to transform
the logical relation as a compositionnal interpretation of terms. We
think that exploring this option is another way to extend the project.
\input{figures/logrelComp}

* Conclusion
Logical relations are a proof technique that has been widely studied in the
past decades, and that have proven very useful to prove
programming language properties. While doing proof on paper is prone to
mistakes, proof assistants such as Coq tend to give some stronger guarantees.
Coq carefully manages every minute detail and ensures that every single
lemma is proven. On the other hand, it requires carefully choosing the
implementation representations in order to make the proofs more manageable.

\printbibliography[heading=none]
